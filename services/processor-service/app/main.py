# FILE: ./services/processor-service/app/main.py
# (Ù†Ø³Ø®Ù‡ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ùˆ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ)

import logging
import os
import json
import requests
from typing import Optional, List
import threading

from dotenv import load_dotenv

# Google Gen AI SDK
from google import genai
from google.genai import types
from pydantic import BaseModel

# Project-shared utilities
from common.logging_config import setup_logging
from common.rabbit import RabbitMQClient

# ---------------------------
# Environment & Config
# ---------------------------
load_dotenv()

# --- Ù†Ø§Ù… ØµÙâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ ---
POST_CREATED_QUEUE = os.getenv("POST_CREATED_QUEUE", "post_created_queue")
CONTENT_PROCESSING_QUEUE = os.getenv("CONTENT_PROCESSING_QUEUE", "content_processing_queue")
REVIEW_NOTIFICATIONS_QUEUE = "review_notifications_queue" 
FINAL_APPROVAL_NOTIFICATIONS_QUEUE = "final_approval_notifications_queue"
MANAGEMENT_API_URL = os.getenv("MANAGEMENT_API_URL", "http://management-api:8000")

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")

setup_logging()
logger = logging.getLogger("processor-service-v2")

# ---------------------------
# Structured Output Schemas
# ---------------------------
# Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø±Ø­Ù„Ù‡ Ø§ÙˆÙ„: Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´
class PreProcessOutput(BaseModel):
    title_translated: str
    quality_score: float  # 0..10

# Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø±Ø­Ù„Ù‡ Ø¯ÙˆÙ…: Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§
class ContentProcessOutput(BaseModel):
    content_translated: Optional[str] = None
    content_telegram: Optional[str] = None
    content_instagram: Optional[str] = None
    content_twitter: Optional[str] = None

# ---------------------------
# Gemini Client
# ---------------------------
try:
    client = genai.Client(api_key=GEMINI_API_KEY) if GEMINI_API_KEY else genai.Client()
    logger.info("âœ… Gemini client initialized (google-genai)")
except Exception as e:
    client = None
    logger.critical(f"âŒ Failed to initialize Gemini client: {e}", exc_info=True)

# ---------------------------
# HTTP Helpers
# ---------------------------
def get_post_details(post_id: int):
    # ... (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ...
    try:
        resp = requests.get(f"{MANAGEMENT_API_URL}/posts/{post_id}")
        resp.raise_for_status()
        return resp.json()
    except requests.exceptions.RequestException as e:
        logger.error(f"Could not fetch details for post_id={post_id}: {e}")
        return None

def save_preprocessing_result(post_id: int, result: PreProcessOutput, featured_image_url: Optional[str]):
    """Ù†ØªØ§ÛŒØ¬ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ùˆ ÛŒÚ© Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ Ù…Ø¯ÛŒØ± Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    payload = {
        "language": "fa",
        "title_translated": result.title_translated,
        "score": result.quality_score,
        "featured_image_url": featured_image_url
    }
    try:
        # Û±. Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        requests.post(f"{MANAGEMENT_API_URL}/posts/{post_id}/translations", json=payload).raise_for_status()
        logger.info(f"âœ… Saved preprocessing result for post_id={post_id}")
        
        # Û². ØªØºÛŒÛŒØ± ÙˆØ¶Ø¹ÛŒØª Ù¾Ø³Øª
        requests.post(f"{MANAGEMENT_API_URL}/posts/{post_id}/preprocessed").raise_for_status()
        logger.info(f"âœ… Post status set to PREPROCESSED for post_id={post_id}")

        # Û³. Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ Ù…Ø¯ÛŒØ± ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø² Ø·Ø±ÛŒÙ‚ RabbitMQ
        with RabbitMQClient() as rmq:
            message_body = json.dumps({"post_id": post_id})
            rmq.channel.queue_declare(queue=REVIEW_NOTIFICATIONS_QUEUE, durable=True)
            rmq.publish(exchange_name="", routing_key=REVIEW_NOTIFICATIONS_QUEUE, body=message_body)
            logger.info(f"ğŸ“¤ Sent review notification for post_id={post_id}")
            
        return True
    except Exception as e:
        logger.error(f"Could not save preprocessing result or notify for post_id={post_id}: {e}")
        return False

def update_translation_with_content(translation_id: int, post_id: int, result: ContentProcessOutput):
    """ØªØ±Ø¬Ù…Ù‡ Ø±Ø§ Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¢Ù¾Ø¯ÛŒØª Ú©Ø±Ø¯Ù‡ Ùˆ Ù¾ÛŒØ§Ù…ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ§ÛŒÛŒØ¯ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø¯ÛŒØ± Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    
    # --- START: Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø§Ø³Øª ---
    payload = result.model_dump(exclude_unset=True)
    payload['language'] = 'fa' # ÙÛŒÙ„Ø¯ Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø²Ø¨Ø§Ù† Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    # --- END: Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ ---

    try:
        # Û±. Ø¢Ù¾Ø¯ÛŒØª ØªØ±Ø¬Ù…Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        requests.patch(f"{MANAGEMENT_API_URL}/translations/{translation_id}", json=payload).raise_for_status()
        logger.info(f"âœ… Updated translation with content for translation_id={translation_id}")
        
        # Û². ØªØºÛŒÛŒØ± ÙˆØ¶Ø¹ÛŒØª Ù¾Ø³Øª
        requests.post(f"{MANAGEMENT_API_URL}/posts/{post_id}/ready-for-final-approval").raise_for_status()
        logger.info(f"âœ… Post status set to READY_FOR_FINAL_APPROVAL for post_id={post_id}")
        
        # Û³. Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ Ù…Ø¯ÛŒØ± ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ø§ÛŒ ØªØ§ÛŒÛŒØ¯ Ù†Ù‡Ø§ÛŒÛŒ
        with RabbitMQClient() as rmq:
            message_body = json.dumps({"post_id": post_id})
            rmq.channel.queue_declare(queue=FINAL_APPROVAL_NOTIFICATIONS_QUEUE, durable=True)
            rmq.publish(exchange_name="", routing_key=FINAL_APPROVAL_NOTIFICATIONS_QUEUE, body=message_body)
            logger.info(f"ğŸ“¤ Sent final approval notification for post_id={post_id}")
            
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"Could not update translation or notify for post_id={post_id}: {e}")
        return False

# ---------------------------
# Core AI Processing
# ---------------------------
def _safety_settings():
    # ... (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ...
    pass

def preprocess_title_and_score(title: str, model: str = "gemini-2.5-flash") -> PreProcessOutput:
    """Ù…Ø±Ø­Ù„Ù‡ Û±: ÙÙ‚Ø· Ø¹Ù†ÙˆØ§Ù† Ø±Ø§ ØªØ±Ø¬Ù…Ù‡ Ùˆ Ø¨Ù‡ Ø¢Ù† Ø§Ù…ØªÛŒØ§Ø² Ù…ÛŒâ€ŒØ¯Ù‡Ø¯."""
    if not client:
        raise RuntimeError("Gemini client not initialized")

    sys_instruction = (
        "You are a professional Persian translator and editor. "
        "Return ONLY JSON with fields: title_translated (string), quality_score (number). "
        "Requirements: "
        "1) Translate the title to fluent, engaging Persian. "
        "2) quality_score in [0,10] reflecting translation fidelity and clarity; use a dot for decimals."
    )
    prompt = f'**Title:** "{title or ""}"'

    resp = client.models.generate_content(
        model=model,
        contents=prompt,
        config=types.GenerateContentConfig(
            system_instruction=sys_instruction,
            response_mime_type="application/json",
            response_schema=PreProcessOutput,
            temperature=0.2,
            safety_settings=_safety_settings(),
        ),
    )
    return resp.parsed

def process_content_for_platforms(content: str, platforms: List[str], model: str = "gemini-2.5-flash") -> ContentProcessOutput:
    """Ù…Ø±Ø­Ù„Ù‡ Û²: Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ù„ØªÙØ±Ù…â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ Ùˆ Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ù‚ÛŒÙ‚ Ù‡Ø²ÛŒÙ†Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if not client:
        raise RuntimeError("Gemini client not initialized")

    # --- START: Ù…Ù†Ø·Ù‚ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ù¾Ø±Ø§Ù…Ù¾Øª ---
    
    # Ø§Ú¯Ø± Ø¨ÛŒØ´ Ø§Ø² ÛŒÚ© Ù¾Ù„ØªÙØ±Ù… Ø¯Ø± Ù„ÛŒØ³Øª Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ù‡ Ù…Ø¹Ù†ÛŒ "ØªØ§ÛŒÛŒØ¯ Ú©Ù„" Ø§Ø³Øª
    is_approve_all = len(platforms) > 1

    platform_requirements = []
    
    if is_approve_all:
        # Ø­Ø§Ù„Øª Ú©Ø§Ù…Ù„: Ø§Ø¨ØªØ¯Ø§ ØªØ±Ø¬Ù…Ù‡ Ú©Ø§Ù…Ù„ØŒ Ø³Ù¾Ø³ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡
        platform_requirements.append("1. First, translate the entire original **Content** into fluent Persian. The result MUST be in the 'content_translated' field.")
        platform_requirements.append("2. From the translated content, generate 'content_telegram': A concise Persian summary, under 1000 characters.")
        platform_requirements.append("3. From the translated content, generate 'content_instagram': An engaging Persian summary for Instagram, under 2200 characters, with relevant hashtags.")
        platform_requirements.append("4. From the translated content, generate 'content_twitter': A very short Persian summary for Twitter/X, under 280 characters.")
    else:
        # Ø­Ø§Ù„Øª Ø¨Ù‡ÛŒÙ†Ù‡: ÙÙ‚Ø· Ø®Ù„Ø§ØµÙ‡ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ù¾Ù„ØªÙØ±Ù… Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡
        target_platform = platforms[0] # Ú†ÙˆÙ† Ø¯Ø± Ø§ÛŒÙ† Ø­Ø§Ù„Øª ÙÙ‚Ø· ÛŒÚ© Ù¾Ù„ØªÙØ±Ù… Ø¯Ø§Ø±ÛŒÙ…
        if target_platform == "telegram":
            platform_requirements.append("- Directly translate and summarize the original English **Content** into a concise Persian summary for Telegram. The result MUST be in the 'content_telegram' field and be under 1000 characters. Do NOT provide a full 'content_translated'.")
        elif target_platform == "instagram":
            platform_requirements.append("- Directly translate and summarize the original English **Content** into an engaging Persian summary for Instagram. The result MUST be in the 'content_instagram' field, be under 2200 characters, and include relevant hashtags. Do NOT provide a full 'content_translated'.")
        elif target_platform == "twitter":
            platform_requirements.append("- Directly translate and summarize the original English **Content** into a very short Persian summary for Twitter/X. The result MUST be in the 'content_twitter' field and be under 280 characters. Do NOT provide a full 'content_translated'.")

    sys_instruction = (
        "You are a professional Persian translator and multi-platform copywriter.\n"
        "Return ONLY a JSON object with the requested fields.\n"
        "Instructions:\n" + "\n".join(platform_requirements)
    )
    # --- END: Ù¾Ø§ÛŒØ§Ù† Ù…Ù†Ø·Ù‚ Ù†Ù‡Ø§ÛŒÛŒ ---

    prompt = f'**Content:**\n"{content or ""}"'

    resp = client.models.generate_content(
        model=model,
        contents=prompt,
        config=types.GenerateContentConfig(
            system_instruction=sys_instruction,
            response_mime_type="application/json",
            response_schema=ContentProcessOutput,
            temperature=0.3,
        ),
    )
    return resp.parsed

# ---------------------------
# RabbitMQ Callbacks
# ---------------------------
def on_post_created_callback(ch, method, properties, body):
    """Callback Ø¨Ø±Ø§ÛŒ ØµÙ post_created_queue (Ù…Ø±Ø­Ù„Ù‡ Û±: Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´)"""
    try:
        message = json.loads(body)
        post_id = message.get("post_id")
        if not post_id:
            logger.warning("Received message without post_id; acking.")
            ch.basic_ack(delivery_tag=method.delivery_tag)
            return

        logger.info(f"ğŸ“¬ [PREPROCESS] Received post_created for post_id={post_id}")
        post_details = get_post_details(post_id)
        if not post_details:
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
            return

        title = post_details.get("title_original")
        result = preprocess_title_and_score(title)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§ÙˆÙ„ÛŒÙ† ØªØµÙˆÛŒØ± Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªØµÙˆÛŒØ± Ø´Ø§Ø®Øµ
        featured_image_url = (post_details.get("images")[0].get("url") 
                              if post_details.get("images") else None)

        save_preprocessing_result(post_id, result, featured_image_url)
        logger.info(f"âœ… [PREPROCESS] Finished for post_id={post_id}")
        ch.basic_ack(delivery_tag=method.delivery_tag)

    except Exception as e:
        logger.error(f"Failed to preprocess message: {e}", exc_info=True)
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)

# FILE: ./services/processor-service/app/main.py

def on_content_processing_callback(ch, method, properties, body):
    """Callback Ø¨Ø±Ø§ÛŒ ØµÙ content_processing_queue (Ù…Ø±Ø­Ù„Ù‡ Û²: Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§)"""
    try:
        message = json.loads(body)
        post_id = message.get("post_id")
        platforms = message.get("platforms", [])
        if not post_id or not platforms:
            logger.warning("Received invalid content processing request; acking.")
            ch.basic_ack(delivery_tag=method.delivery_tag)
            return
        
        logger.info(f"ğŸ“¬ [PROCESS CONTENT] Received request for post_id={post_id}, platforms={platforms}")
        post_details = get_post_details(post_id)
        if not post_details or not post_details.get("translations"):
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
            return

        content = post_details.get("content_original")
        result = process_content_for_platforms(content, platforms)
        
        translation_id = post_details["translations"][0]["id"]
        
        # --- START: Ø§ÛŒÙ† Ø®Ø· Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø§Ø³Øª ---
        # Ù…Ø§ post_id Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÙˆØ±ÙˆØ¯ÛŒ Ø³ÙˆÙ… Ø¨Ù‡ ØªØ§Ø¨Ø¹ Ù¾Ø§Ø³ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
        if update_translation_with_content(translation_id, post_id, result):
        # --- END: Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ ---
            logger.info(f"âœ… [PROCESS CONTENT] Finished for post_id={post_id}")
            ch.basic_ack(delivery_tag=method.delivery_tag)
        else:
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)

    except Exception as e:
        logger.error(f"Failed to process content message: {e}", exc_info=True)
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)

# ---------------------------
# Main Function
# ---------------------------
def main():
    logger.info("--- ğŸ§  Processor Service V2 Started ---")
    if not client:
        logger.critical("âŒ Gemini client is not available; exiting.")
        return

    # Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ø± listener Ø¯Ø± ÛŒÚ© thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
    def listen(queue_name, callback_func):
        with RabbitMQClient() as rmq:
            rmq.channel.queue_declare(queue=queue_name, durable=True)
            logger.info(f"Waiting for messages in '{queue_name}'...")
            rmq.start_consuming(queue_name=queue_name, callback=callback_func)

    preprocess_thread = threading.Thread(target=listen, args=(POST_CREATED_QUEUE, on_post_created_callback))
    content_process_thread = threading.Thread(target=listen, args=(CONTENT_PROCESSING_QUEUE, on_content_processing_callback))

    preprocess_thread.start()
    content_process_thread.start()

    preprocess_thread.join()
    content_process_thread.join()

if __name__ == "__main__":
    main()